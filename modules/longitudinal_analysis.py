# ===============================================================
# üåê EmentaLabv2 ‚Äî Mapa de Conectividade Curricular (v1.1)
# ===============================================================
# (mant√©m nome longitudinal_analysis.py por compatibilidade)
# - Constr√≥i rede de impacto entre UCs via similaridade sem√¢ntica (SBERT)
# - Mede centralidade (grau, intermedia√ß√£o, densidade)
# - Gera grafo, tabela e relat√≥rio anal√≠tico via GPT
# ===============================================================

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx
from openai import OpenAI

from utils.embeddings import sbert_embed, l2_normalize
from utils.text_utils import find_col
from utils.exportkit import export_table, export_zip_button, show_and_export_fig


# ---------------------------------------------------------------
# üöÄ Fun√ß√£o principal
# ---------------------------------------------------------------
def run_longitudinal(df, scope_key, client=None):
    st.header("üåê Mapa de Conectividade Curricular (Rede de Impacto)")
    st.caption(
        """
        Mapeia as **rela√ß√µes sem√¢nticas entre Unidades Curriculares (UCs)**, revelando disciplinas
        **estruturantes**, **intermedi√°rias** e **perif√©ricas** dentro do curso. 
        A an√°lise combina embeddings SBERT e m√©tricas de rede para apoiar revis√µes curriculares.
        """
    )

    # -----------------------------------------------------------
    # üìÇ Localiza colunas principais
    # -----------------------------------------------------------
    col_text = (
        find_col(df, "Ementa")
        or find_col(df, "Descri√ß√£o")
        or find_col(df, "Objetos de conhecimento")
    )
    col_uc = find_col(df, "Nome da UC")

    if not col_uc or not col_text:
        st.error("N√£o foram encontradas colunas adequadas ('Nome da UC' e 'Ementa' ou similar).")
        return

    df_valid = df[[col_uc, col_text]].dropna().rename(columns={col_uc: "UC", col_text: "Texto"})
    if df_valid.empty:
        st.warning("Nenhuma UC com texto preenchido.")
        return

    max_uc = st.slider("Quantidade de UCs para an√°lise", 4, min(50, len(df_valid)), min(20, len(df_valid)), 1)
    df_valid = df_valid.head(max_uc)

    # -----------------------------------------------------------
    # üß† Embeddings e matriz de similaridade
    # -----------------------------------------------------------
    with st.spinner("üß† Calculando embeddings SBERT..."):
        emb = l2_normalize(sbert_embed(df_valid["Texto"].astype(str).tolist()))
        sims = np.dot(emb, emb.T)

    df_sim = pd.DataFrame(sims, index=df_valid["UC"], columns=df_valid["UC"])
    export_table(scope_key, df_sim, "matriz_similaridade", "Matriz de Similaridade entre UCs")

    # Heatmap compacto
    fig, ax = plt.subplots(figsize=(7, 5))
    sns.heatmap(df_sim, cmap="crest", linewidths=0.4)
    ax.set_title("Similaridade entre UCs (SBERT)", fontsize=11)
    st.pyplot(fig, use_container_width=True)
    show_and_export_fig(scope_key, fig, "mapa_similaridade_semantica")

    # -----------------------------------------------------------
    # üï∏Ô∏è Rede de conectividade
    # -----------------------------------------------------------
    threshold = st.slider("Limite de conex√£o (similaridade m√≠nima)", 0.5, 0.95, 0.75, 0.05)
    G = nx.Graph([(a, b, {"weight": sims[i, j]})
                  for i, a in enumerate(df_valid["UC"])
                  for j, b in enumerate(df_valid["UC"])
                  if i < j and sims[i, j] >= threshold])

    if G.number_of_edges() == 0:
        st.warning("Nenhuma conex√£o encontrada com o limite atual. Reduza o threshold.")
        return

    # -----------------------------------------------------------
    # üìä M√©tricas de centralidade
    # -----------------------------------------------------------
    grau = nx.degree_centrality(G)
    inter = nx.betweenness_centrality(G)
    densidade = nx.density(G)

    df_centralidade = pd.DataFrame({
        "UC": list(G.nodes),
        "Centralidade Grau": [grau[n] for n in G.nodes],
        "Centralidade Intermedia√ß√£o": [inter[n] for n in G.nodes],
    }).sort_values("Centralidade Grau", ascending=False)

    st.markdown("### üìà Disciplinas Estruturantes e Intermedi√°rias")
    st.dataframe(df_centralidade, use_container_width=True)
    export_table(scope_key, df_centralidade, "centralidade_uc", "Centralidade das UCs")

    # -----------------------------------------------------------
    # üé® Visualiza√ß√£o do grafo
    # -----------------------------------------------------------
    st.markdown("### üé® Rede de Impacto Curricular")
    pos = nx.spring_layout(G, seed=42, k=0.6)
    fig, ax = plt.subplots(figsize=(10, 7))
    nx.draw_networkx_nodes(G, pos, node_size=700, node_color="#A5D8FF", edgecolors="#1E88E5")
    nx.draw_networkx_edges(G, pos, width=1.5, alpha=0.7, edge_color="#64B5F6")
    nx.draw_networkx_labels(G, pos, font_size=8)
    plt.title("Mapa de Conectividade Curricular", fontsize=12, fontweight="bold")
    plt.axis("off")
    st.pyplot(fig, use_container_width=True)
    show_and_export_fig(scope_key, fig, "grafo_conectividade_curricular")

    # -----------------------------------------------------------
    # üß† Relat√≥rio Anal√≠tico via GPT (opcional)
    # -----------------------------------------------------------
    api_key = st.session_state.get("global_api_key", "") if client is None else None
    if api_key:
        client = OpenAI(api_key=api_key)

    if client is not None:
        top_uc = df_centralidade.head(5)["UC"].tolist()
        bottom_uc = df_centralidade.tail(5)["UC"].tolist()

        resumo = (
            f"Foram analisadas {len(G.nodes)} UCs com densidade m√©dia de {densidade:.2f}. "
            f"As UCs mais conectadas (estruturantes) s√£o: {', '.join(top_uc)}. "
            f"As menos conectadas (perif√©ricas) s√£o: {', '.join(bottom_uc)}."
        )

        prompt = (
            "Voc√™ √© um avaliador curricular. Com base no resumo a seguir, produza um relat√≥rio breve, t√©cnico e direto, "
            "destacando **pontos fortes**, **fragilidades** e **sugest√µes de melhoria** da estrutura curricular.\n\n"
            f"{resumo}"
        )

        try:
            with st.spinner("üìÑ Gerando relat√≥rio anal√≠tico via GPT..."):
                resp = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.2,
                )
            analise = resp.choices[0].message.content.strip()
            st.markdown("### üßæ Relat√≥rio Anal√≠tico da Estrutura Curricular")
            st.info(analise)
        except Exception as e:
            st.error(f"‚ùå Erro ao gerar relat√≥rio via GPT: {e}")

    # -----------------------------------------------------------
    # üß≠ Interpreta√ß√£o essencial
    # -----------------------------------------------------------
    st.markdown("---")
    st.markdown(
        """
        ### üß≠ Interpreta√ß√£o dos Resultados
        - **UCs estruturantes:** alta centralidade ‚Üí sustentam o eixo formativo principal.  
        - **UCs intermedi√°rias:** atuam como ponte entre diferentes √°reas de conhecimento.  
        - **UCs perif√©ricas:** baixa centralidade ‚Üí podem indicar especializa√ß√£o ou desconex√£o.  
        - **Densidade elevada:** curr√≠culo coeso e articulado.  
        - **Densidade baixa:** poss√≠veis lacunas entre √°reas.

        üîπ **Aplica√ß√£o:** use este mapa para revisar a coer√™ncia entre disciplinas, identificar redund√¢ncias
        e fortalecer a integra√ß√£o entre eixos formativos.
        """
    )

    export_zip_button(scope_key)
