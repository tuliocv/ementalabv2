# ===============================================================
# üìà EmentaLabv2 ‚Äî Clusteriza√ß√£o (Ementa) c/ UC_ID, Nome GPT e Compara√ß√£o
# ===============================================================
import json
import re
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import streamlit as st

from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_distances

# Utils do projeto
from utils.embeddings import l2_normalize, sbert_embed
from utils.exportkit import export_table, show_and_export_fig, export_zip_button
from utils.text_utils import find_col, replace_semicolons

# -------------- Helpers -----------------

def _clean_corpus(textos: list[str]) -> list[str]:
    """Limpa e padroniza os textos."""
    out = []
    for t in textos:
        s = str(t)
        s = re.sub(r"[\r\n\t]+", " ", s)      # quebras
        s = re.sub(r"\s{2,}", " ", s).strip() # espa√ßos
        out.append(s)
    return out

def _tfidf_top_keywords_per_cluster(textos: list[str], labels: np.ndarray, top_k: int = 8) -> pd.DataFrame:
    """
    Retorna um DataFrame com palavras-chave por cluster.
    Usa par√¢metros compat√≠veis com sklearn 1.4+ (evita InvalidParameterError).
    """
    if len(textos) == 0:
        return pd.DataFrame(columns=["Cluster", "Palavras-chave"])

    textos_clean = _clean_corpus(textos)

    # Vectorizer enxuto e compat√≠vel
    vectorizer = TfidfVectorizer(
        lowercase=True,
        analyzer="word",
        ngram_range=(1, 2),
        min_df=2,
        max_df=0.95,
        max_features=8000,
        norm="l2"
    )

    X = vectorizer.fit_transform(textos_clean)
    vocab = np.array(vectorizer.get_feature_names_out())

    df_kw = []
    k = int(labels.max()) + 1 if len(labels) else 0
    for cid in range(k):
        idx = np.where(labels == cid)[0]
        if idx.size == 0:
            df_kw.append({"Cluster": cid, "Palavras-chave": []})
            continue
        sub = X[idx].mean(axis=0)  # m√©dia TF-IDF do cluster
        sub = np.asarray(sub).ravel()
        if sub.sum() == 0:
            df_kw.append({"Cluster": cid, "Palavras-chave": []})
            continue
        top_idx = np.argsort(-sub)[:top_k]
        kws = [vocab[i] for i in top_idx]
        df_kw.append({"Cluster": cid, "Palavras-chave": kws})

    return pd.DataFrame(df_kw)

def _representative_uc_by_centroid(embeddings: np.ndarray, labels: np.ndarray, nomes: list[str]) -> dict:
    """
    Para cada cluster, encontra a UC cujo embedding est√° mais pr√≥ximo do centr√≥ide (menor dist√¢ncia).
    Retorna {cluster_id: {"uc": Nome, "idx": √≠ndice}}.
    """
    reps = {}
    k = int(labels.max()) + 1 if len(labels) else 0
    for cid in range(k):
        idxs = np.where(labels == cid)[0]
        if idxs.size == 0:
            reps[cid] = {"uc": f"Cluster {cid}", "idx": None}
            continue
        C = embeddings[idxs].mean(axis=0, keepdims=True)
        d = cosine_distances(embeddings[idxs], C).ravel()
        best_local = idxs[np.argmin(d)]
        reps[cid] = {"uc": nomes[best_local], "idx": int(best_local)}
    return reps

def _project_2d(emb: np.ndarray) -> np.ndarray:
    """Tenta UMAP ‚Üí T-SNE ‚Üí SVD, nessa ordem."""
    try:
        import umap
        return umap.UMAP(n_neighbors=12, min_dist=0.1, random_state=42).fit_transform(emb)
    except Exception:
        try:
            from sklearn.manifold import TSNE
            perplex = max(2, min(30, emb.shape[0] // 3 if emb.shape[0] >= 6 else 2))
            return TSNE(n_components=2, perplexity=perplex, random_state=42, init="random", learning_rate="auto").fit_transform(emb)
        except Exception:
            from sklearn.decomposition import TruncatedSVD
            return TruncatedSVD(n_components=2, random_state=42).fit_transform(emb)

def _plot_scatter(df_plot: pd.DataFrame, title: str, label_col: str, scope_key: str, base_name: str):
    """Desenha scatter 2D com r√≥tulos UC_ID e legenda por r√≥tulos de cluster."""
    fig, ax = plt.subplots(figsize=(9.5, 6.5))
    labels = df_plot[label_col].astype(str).unique().tolist()
    palette = sns.color_palette("husl", len(labels))

    for i, lab in enumerate(labels):
        sub = df_plot[df_plot[label_col].astype(str) == str(lab)]
        ax.scatter(sub["X"], sub["Y"], s=70, alpha=0.9, color=palette[i], label=str(lab), edgecolor="white", linewidths=0.6)
        # anota UC_ID no ponto
        for _, row in sub.iterrows():
            ax.text(row["X"], row["Y"], str(int(row["UC_ID"])), fontsize=8, ha="center", va="center", color="black", alpha=0.9, clip_on=False)

    ax.set_title(title)
    ax.set_xlabel("Dimens√£o 1")
    ax.set_ylabel("Dimens√£o 2")
    ax.legend(title=label_col, bbox_to_anchor=(1.02, 1), loc="upper left", frameon=False)
    ax.margins(0.05)

    show_and_export_fig(scope_key, fig, base_name)
    plt.close(fig)

def _call_gpt_for_names(clusters_payload: list[dict], api_key: str) -> dict:
    """
    Envia um resumo de cada cluster para o GPT sugerir nomes.
    Retorna dict {cluster_id: "Nome GPT"}.
    """
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
    except Exception:
        st.error("‚ùå N√£o foi poss√≠vel inicializar o cliente OpenAI. Verifique se o pacote `openai` est√° instalado e a chave √© v√°lida.")
        return {}

    prompt = (
        "Voc√™ receber√° um conjunto de clusters de ementas. Para cada cluster, atribua um **nome tem√°tico curto e claro** "
        "(m√°x. 4 palavras), em portugu√™s, que represente o conte√∫do central.\n"
        "Responda **apenas** com JSON no formato:\n"
        "{ \"nomes\": [ {\"cluster\": <id>, \"nome\": \"<Nome do cluster>\"}, ... ] }\n\n"
        "Clusters:\n"
    )
    for c in clusters_payload:
        prompt += f"- Cluster {c['cluster']}: Representante = {c['representante']}; Keywords = {', '.join(c['keywords'][:8])}; Exemplo de ementa: {c['amostra_ementa']}\n"

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            response_format={"type": "json_object"},
        )
        raw = resp.choices[0].message.content or "{}"
        data = json.loads(raw)
        nomes = {}
        for item in data.get("nomes", []):
            cid = int(item.get("cluster"))
            nome = str(item.get("nome", "")).strip()
            if nome:
                nomes[cid] = nome
        return nomes
    except Exception as e:
        st.error(f"‚ùå Erro ao consultar GPT para nomear clusters: {e}")
        return {}

# -------------- M√≥dulo principal -----------------

def run_cluster(df: pd.DataFrame, scope_key: str):
    """
    Clusteriza√ß√£o de ementas com:
      - UC_ID sequencial
      - KMeans (SBERT)
      - Palavras-chave TF-IDF por cluster
      - Nome do cluster = UC representante (centr√≥ide)
      - Nome GPT opcional + gr√°fico comparativo
      - Tabela consolidada com todas as UCs
    """
    st.header("üìà Clusteriza√ß√£o (Ementa)")
    st.markdown("""
**O que √©:** agrupa UCs por similaridade sem√¢ntica das **Ementas** e projeta em 2D (cada ponto = 1 UC).  
**Como analisar:** pontos pr√≥ximos compartilham tema; use os **n√∫meros (UC_ID)** para localizar a UC na tabela.  
**Dicas:** ajuste **K**, confira as **palavras-chave** por cluster e, se quiser, pe√ßa ao **GPT** nomes tem√°ticos.
    """)

    # --------- Coluna base ---------
    col_ementa = find_col(df, "Ementa")
    if not col_ementa:
        st.error("Coluna 'Ementa' n√£o encontrada. Verifique o cabe√ßalho.")
        st.stop()

    df_an = df.dropna(subset=[col_ementa]).copy()
    if df_an.empty:
        st.warning("N√£o h√° ementas v√°lidas para clusterizar.")
        st.stop()

    # Numera√ß√£o sequencial
    df_an = df_an.reset_index(drop=True)
    df_an["UC_ID"] = np.arange(1, len(df_an) + 1)

    textos = df_an[col_ementa].astype(str).apply(replace_semicolons).tolist()
    nomes = df_an["Nome da UC"].astype(str).tolist()

    # --------- Embeddings ---------
    with st.spinner("üß† Calculando embeddings SBERT..."):
        emb = l2_normalize(sbert_embed(textos).astype(np.float32))

    # --------- KMeans ---------
    max_k = min(12, max(2, len(df_an)))
    k = st.slider("N√∫mero de clusters (K)", 2, max_k, min(6, max_k))
    with st.spinner("üßÆ Executando K-Means..."):
        km = KMeans(n_clusters=k, random_state=42, n_init=10)
        labels = km.fit_predict(emb)

    # --------- Representantes e keywords ---------
    with st.spinner("üîé Gerando representantes e palavras-chave..."):
        reps = _representative_uc_by_centroid(emb, labels, nomes)
        df_kw = _tfidf_top_keywords_per_cluster(textos, labels, top_k=8)

    # Nome do cluster (representante)
    cluster_names_initial = {cid: reps[cid]["uc"] for cid in range(k)}

    # --------- Proje√ß√£o 2D ---------
    with st.spinner("üó∫Ô∏è Projetando em 2D..."):
        xy = _project_2d(emb)
    df_plot = pd.DataFrame({"UC_ID": df_an["UC_ID"], "Nome da UC": nomes, "Cluster": labels, "X": xy[:, 0], "Y": xy[:, 1], "Ementa": textos})
    df_plot["Nome do Cluster (Rep.)"] = df_plot["Cluster"].map(cluster_names_initial)

    # --------- Tabela: UCs por Cluster ---------
    st.markdown("### üìã UCs x Clusters (com UC_ID)")
    df_out = df_plot[["UC_ID", "Nome da UC", "Cluster", "Nome do Cluster (Rep.)", "Ementa"]].sort_values(["Cluster", "UC_ID"])
    st.dataframe(df_out, use_container_width=True, height=420)
    export_table(scope_key, df_out, "clusters_ucid", "Clusters_UCIDs")

    # --------- Palavras-chave por cluster ---------
    st.markdown("### üî§ Palavras-chave (TF-IDF) por Cluster")
    if not df_kw.empty:
        df_kw["Nome do Cluster (Rep.)"] = df_kw["Cluster"].map(cluster_names_initial)
        df_kw["Palavras-chave (Top)"] = df_kw["Palavras-chave"].apply(lambda xs: ", ".join(xs) if xs else "‚Äî")
        st.dataframe(df_kw[["Cluster", "Nome do Cluster (Rep.)", "Palavras-chave (Top)"]], use_container_width=True)
        export_table(scope_key, df_kw[["Cluster", "Palavras-chave (Top)"]], "clusters_keywords", "Clusters_Keywords")
    else:
        st.info("N√£o foi poss√≠vel extrair palavras-chave (TF-IDF) para os clusters.")

    # --------- Gr√°fico 1: r√≥tulo baseado no representante ---------
    st.markdown("### üó∫Ô∏è Dispers√£o 2D (r√≥tulo = UC representante)")
    _plot_scatter(
        df_plot.assign(_label=df_plot["Nome do Cluster (Rep.)"]),
        title="Distribui√ß√£o (Ementa) ‚Äî SBERT ‚Äî r√≥tulo por UC representante",
        label_col="_label",
        scope_key=scope_key,
        base_name="cluster_scatter_representante"
    )

    # --------- Nomear com GPT (opcional) ---------
    st.markdown("### ü§ñ Nomear Clusters com GPT (opcional)")
    st.caption("Se desejar, forne√ßa sua OpenAI API Key para o GPT sugerir nomes tem√°ticos curtos para cada cluster.")
    api_key = st.text_input("üîë OpenAI API Key", type="password")

    gpt_names = {}
    if api_key and st.button("üöÄ Sugerir nomes com GPT"):
        # Prepara amostra compacta por cluster
        payload = []
        for cid in range(k):
            ex_idxs = np.where(labels == cid)[0]
            exemplo_ementa = textos[int(ex_idxs[0])] if ex_idxs.size > 0 else ""
            keywords = df_kw.loc[df_kw["Cluster"] == cid, "Palavras-chave"]
            keywords = keywords.iloc[0] if not keywords.empty else []
            payload.append({
                "cluster": int(cid),
                "representante": cluster_names_initial.get(cid, f"Cluster {cid}"),
                "keywords": keywords if isinstance(keywords, list) else [],
                "amostra_ementa": exemplo_ementa[:400]
            })

        with st.spinner("Consultando GPT para nomear clusters..."):
            gpt_names = _call_gpt_for_names(payload, api_key)

        if gpt_names:
            st.success("Nomes sugeridos recebidos!")
        else:
            st.warning("O GPT n√£o retornou nomes. Mantendo r√≥tulos pelos representantes.")

    # --------- Compara√ß√£o Antes x Depois (se houver GPT) ---------
    if gpt_names:
        df_names = pd.DataFrame({
            "Cluster": list(range(k)),
            "Nome (Rep.)": [cluster_names_initial[c] for c in range(k)],
            "Nome GPT": [gpt_names.get(c, cluster_names_initial[c]) for c in range(k)]
        })
        st.markdown("### üîÅ Compara√ß√£o de nomes (Antes √ó Depois)")
        st.dataframe(df_names, use_container_width=True)
        export_table(scope_key, df_names, "clusters_nomes_antes_depois", "Clusters_Nomes_Comparacao")

        # Gr√°fico 2 com r√≥tulo GPT
        df_plot["Nome GPT"] = df_plot["Cluster"].map(lambda c: gpt_names.get(int(c), cluster_names_initial[int(c)]))
        st.markdown("### üó∫Ô∏è Dispers√£o 2D (r√≥tulo = Nome GPT)")
        _plot_scatter(
            df_plot.assign(_label=df_plot["Nome GPT"]),
            title="Distribui√ß√£o (Ementa) ‚Äî SBERT ‚Äî r√≥tulo por Nome GPT",
            label_col="_label",
            scope_key=scope_key,
            base_name="cluster_scatter_gpt"
        )

    # --------- Tabela Consolidada (todas as UCs + nomes GPT, se existirem) ---------
    st.markdown("### üìã Tabela Consolidada ‚Äî Todas as UCs e Clusters")
    if gpt_names:
        df_full = df_out.merge(
            pd.DataFrame({
                "Cluster": list(range(k)),
                "Nome GPT": [gpt_names.get(c, cluster_names_initial[c]) for c in range(k)]
            }),
            on="Cluster",
            how="left"
        )
    else:
        df_full = df_out.copy()
        df_full["Nome GPT"] = "‚Äî"

    df_full = df_full[["UC_ID", "Nome da UC", "Cluster", "Nome do Cluster (Rep.)", "Nome GPT", "Ementa"]]
    st.dataframe(df_full, use_container_width=True, height=480)
    export_table(scope_key, df_full, "cluster_consolidado", "UCs e Clusters Consolidados")

     # -----------------------------------------------------------
    # üìò Interpreta√ß√£o pedag√≥gica
    # -----------------------------------------------------------
    st.markdown("---")
    st.subheader("üìò Como interpretar os resultados")
    st.markdown(
        """
        **1Ô∏è‚É£ Significado dos clusters:**
        - Cada grupo re√∫ne UCs com **ementas semanticamente semelhantes**.
        - UCs pr√≥ximas compartilham **conte√∫dos, abordagens e compet√™ncias** similares.

        **2Ô∏è‚É£ Interpreta√ß√£o pr√°tica:**
        - Clusters grandes indicam **n√∫cleos formativos amplos** (ex.: Matem√°tica, Programa√ß√£o, Gest√£o).  
        - Clusters pequenos podem sinalizar **especializa√ß√µes** ou **redund√¢ncias curriculares**.  
        - A UC representativa indica **a disciplina mais central** dentro do tema.

        **3Ô∏è‚É£ Uso com GPT:**
        - O nome sugerido pelo GPT ajuda a **etiquetar os n√∫cleos tem√°ticos** de forma interpret√°vel.
        - Ideal para relat√≥rios de an√°lise curricular, consolida√ß√£o de PPCs e reuni√µes de NDE.

        **4Ô∏è‚É£ Comparativo p√≥s-GPT:**
        - O gr√°fico final evidencia como o GPT reorganizou semanticamente os clusters,
          ajudando a alinhar estat√≠sticas a significados pedag√≥gicos.

        **5Ô∏è‚É£ Aplica√ß√µes pr√°ticas:**
        - Diagn√≥stico de **redund√¢ncia e sobreposi√ß√£o curricular**.
        - Identifica√ß√£o de **√°reas interdisciplinares** emergentes.
        - Planejamento de **integra√ß√£o entre clusters correlatos**.
        """
    )
