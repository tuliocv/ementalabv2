# ===============================================================
# üìà EmentaLabv2 ‚Äî Clusteriza√ß√£o (Ementas) + Nomea√ß√£o via GPT
# ===============================================================
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS
from openai import OpenAI

from utils.embeddings import l2_normalize, sbert_embed
from utils.exportkit import export_table, show_and_export_fig, export_zip_button
from utils.text_utils import find_col, replace_semicolons

# ---------------------------------------------------------------
# Fun√ß√£o principal
# ---------------------------------------------------------------
def run_cluster(df, scope_key):
    # -----------------------------------------------------------
    # üè∑Ô∏è T√≠tulo e descri√ß√£o
    # -----------------------------------------------------------
    st.markdown(
        "<h2 style='color:#2ca02c;'>üìà Clusteriza√ß√£o de Ementas</h2>",
        unsafe_allow_html=True
    )
    st.caption(
        """
        Esta an√°lise agrupa as **Ementas das Unidades Curriculares (UCs)** com base em similaridade sem√¢ntica.
        Utiliza **embeddings SBERT** e o algoritmo **K-Means** para revelar **n√∫cleos tem√°ticos** e **√°reas de converg√™ncia curricular**.
        """
    )

    # -----------------------------------------------------------
    # üìÇ Sele√ß√£o da coluna base
    # -----------------------------------------------------------
    col_ementa = find_col(df, "Ementa")
    if not col_ementa:
        st.error("Coluna 'Ementa' n√£o encontrada.")
        st.stop()

    df_an = df.dropna(subset=[col_ementa])
    textos = df_an[col_ementa].astype(str).apply(replace_semicolons).tolist()
    nomes = df_an["Nome da UC"].astype(str).tolist()

    # -----------------------------------------------------------
    # üß† Gera√ß√£o de embeddings (com cache)
    # -----------------------------------------------------------
    @st.cache_data(show_spinner=False)
    def get_embeddings(textos):
        return l2_normalize(sbert_embed(textos))

    with st.spinner("üß† Calculando embeddings sem√¢nticos (SBERT)..."):
        emb = get_embeddings(textos)

    # -----------------------------------------------------------
    # üî¢ Defini√ß√£o do n√∫mero de clusters
    # -----------------------------------------------------------
    st.markdown("### üî¢ Defini√ß√£o do n√∫mero de clusters (K)")
    if st.checkbox("Sugerir K automaticamente (m√©todo do cotovelo)", value=False):
        distortions = []
        K_range = range(2, 10)
        for k in K_range:
            km = KMeans(n_clusters=k, random_state=42)
            km.fit(emb)
            distortions.append(km.inertia_)

        fig, ax = plt.subplots()
        ax.plot(K_range, distortions, marker="o", color="#2ca02c")
        ax.set_xlabel("N√∫mero de Clusters (K)")
        ax.set_ylabel("Soma dos Erros Quadr√°ticos (In√©rcia)")
        ax.set_title("M√©todo do Cotovelo (Elbow Method)")
        show_and_export_fig(scope_key, fig, "cluster_elbow_method")
        st.info("üìä Observe o ponto de inflex√£o do gr√°fico (cotovelo). Ele indica o K mais adequado.")

    # -----------------------------------------------------------
    # üß© Clusteriza√ß√£o manual
    # -----------------------------------------------------------
    k = st.slider("N√∫mero de clusters (K)", 2, 10, 5)
    km = KMeans(n_clusters=k, random_state=42)
    labels = km.fit_predict(emb)

    df_out = pd.DataFrame({
        "Nome da UC": nomes,
        "Cluster": labels,
        "Ementa": textos
    })

    # -----------------------------------------------------------
    # üßÆ Determina√ß√£o da UC representativa (mais pr√≥xima do centr√≥ide)
    # -----------------------------------------------------------
    representative_ucs = []
    for c in range(k):
        cluster_points = emb[labels == c]
        centroid = km.cluster_centers_[c]
        distances = np.linalg.norm(cluster_points - centroid, axis=1)
        idx = np.argmin(distances)
        uc_name = df_out[df_out["Cluster"] == c]["Nome da UC"].iloc[idx]
        representative_ucs.append(uc_name)

    # -----------------------------------------------------------
    # üß© Palavras-chave por cluster (corrigido)
    # -----------------------------------------------------------
    st.markdown("### üß© T√≥picos predominantes por Cluster")

    # ‚úÖ Lista de stopwords compat√≠vel com qualquer vers√£o do sklearn
    base_stopwords = list(ENGLISH_STOP_WORDS)
    extra_stopwords_pt = [
        "de", "da", "do", "das", "dos", "para", "por", "com", "a", "o", "e", "em",
        "como", "ao", "na", "no", "nas", "nos", "sobre", "entre", "pelas", "pelos",
        "pelo", "pela", "ser", "estar", "ter", "se", "que", "onde", "quando", "uma",
        "um", "as", "os", "√©", "das", "dos", "nas", "nos"
    ]
    all_stopwords = base_stopwords + extra_stopwords_pt

    vectorizer = CountVectorizer(
        stop_words=all_stopwords,
        max_features=1000,
        token_pattern=r"(?u)\b\w\w+\b"
    )

    X = vectorizer.fit_transform(textos)
    words = np.array(vectorizer.get_feature_names_out())

    cluster_keywords = []
    for c in range(k):
        mask = (labels == c)
        cluster_texts = X[mask].sum(axis=0).A1
        top_idx = cluster_texts.argsort()[-10:][::-1]
        top_words = words[top_idx]
        cluster_keywords.append({
            "Cluster": c,
            "UC Representativa": representative_ucs[c],
            "Palavras-Chave": ", ".join(top_words)
        })

    df_keywords = pd.DataFrame(cluster_keywords)
    st.dataframe(df_keywords, use_container_width=True)

    # -----------------------------------------------------------
    # üß≠ Visualiza√ß√£o PCA 2D
    # -----------------------------------------------------------
    st.markdown("### üß≠ Visualiza√ß√£o dos Clusters (PCA 2D)")
    pca = PCA(n_components=2, random_state=42)
    reduced = pca.fit_transform(emb)
    df_pca = pd.DataFrame({
        "x": reduced[:, 0], "y": reduced[:, 1],
        "Cluster": labels, "Nome da UC": nomes
    })

    fig, ax = plt.subplots(figsize=(8, 6))
    sns.scatterplot(data=df_pca, x="x", y="y", hue="Cluster", palette="tab10", s=80, ax=ax)
    ax.set_title("Proje√ß√£o dos Clusters de Ementas (PCA)")
    ax.set_xlabel("Componente Principal 1")
    ax.set_ylabel("Componente Principal 2")
    ax.legend(title="Cluster")
    show_and_export_fig(scope_key, fig, "cluster_pca_2d")

    # -----------------------------------------------------------
    # ü§ñ Nomea√ß√£o autom√°tica dos clusters (GPT opcional)
    # -----------------------------------------------------------
    st.markdown("---")
    st.subheader("ü§ñ Nomea√ß√£o Inteligente dos Clusters (opcional)")

    api_key = st.text_input("üîë OpenAI API Key (opcional para nomea√ß√£o GPT)", type="password")
    if api_key:
        client = OpenAI(api_key=api_key)
        st.info("O modelo GPT analisar√° os t√≥picos e sugerir√° nomes representativos para cada cluster.")
        cluster_names = []

        with st.spinner("üß† Gerando nomes sugestivos para os clusters..."):
            for _, row in df_keywords.iterrows():
                prompt = f"""
                Voc√™ √© um especialista em educa√ß√£o superior e an√°lise curricular.
                D√™ um nome tem√°tico curto e representativo para o seguinte cluster de disciplinas:

                UC representativa: {row['UC Representativa']}
                Palavras-chave: {row['Palavras-Chave']}

                Responda apenas com o nome proposto (sem explica√ß√µes adicionais).
                """
                try:
                    resp = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[{"role": "user", "content": prompt}],
                        temperature=0.3,
                    )
                    nome_cluster = resp.choices[0].message.content.strip().replace('"', '')
                    cluster_names.append(nome_cluster)
                except Exception as e:
                    cluster_names.append(f"Erro: {str(e)}")

        df_keywords["Nome GPT"] = cluster_names
        st.dataframe(df_keywords, use_container_width=True)
        export_table(scope_key, df_keywords, "cluster_keywords_gpt", "Clusters Nomeados GPT")
    else:
        st.info("Insira sua chave de API para permitir que o GPT nomeie os clusters.")

    # -----------------------------------------------------------
    # üíæ Exporta√ß√£o dos resultados
    # -----------------------------------------------------------
    export_table(scope_key, df_out, "clusterizacao", "Clusters (Ementa)")
    export_table(scope_key, df_keywords, "cluster_keywords", "Palavras-Chave por Cluster")
    export_zip_button(scope_key)

    # -----------------------------------------------------------
    # üìò Interpreta√ß√£o pedag√≥gica
    # -----------------------------------------------------------
    st.markdown("---")
    st.subheader("üìò Como interpretar os resultados")
    st.markdown(
        """
        **1Ô∏è‚É£ Significado dos clusters:**
        - Cada grupo re√∫ne UCs com **ementas semanticamente semelhantes**.
        - UCs pr√≥ximas compartilham **conte√∫dos, abordagens e compet√™ncias** similares.

        **2Ô∏è‚É£ Interpreta√ß√£o pr√°tica:**
        - Clusters grandes indicam **n√∫cleos formativos amplos** (ex.: Matem√°tica, Programa√ß√£o, Gest√£o).  
        - Clusters pequenos podem sinalizar **especializa√ß√µes** ou **redund√¢ncias curriculares**.  
        - A UC representativa indica **a disciplina mais central** dentro do tema.

        **3Ô∏è‚É£ Uso com GPT:**
        - O nome sugerido pelo GPT ajuda a **etiquetar os n√∫cleos tem√°ticos** de forma interpret√°vel.
        - Ideal para relat√≥rios de an√°lise curricular, consolida√ß√£o de PPCs e reuni√µes de NDE.

        **4Ô∏è‚É£ Aplica√ß√µes pr√°ticas:**
        - Diagn√≥stico de **redund√¢ncia e sobreposi√ß√£o curricular**.
        - Identifica√ß√£o de **√°reas interdisciplinares** emergentes.
        - Planejamento de **integra√ß√£o entre clusters correlatos**.
        """
    )
