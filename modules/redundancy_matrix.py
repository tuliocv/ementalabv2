# ===============================================================
# ğŸ§¬ EmentaLabv2 â€” RedundÃ¢ncia e AnÃ¡lise Frase-a-Frase (v9.3)
# ===============================================================
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import cosine_similarity
from utils.embeddings import l2_normalize, sbert_embed
from utils.exportkit import export_table, export_zip_button
from utils.text_utils import (
    find_col,
    replace_semicolons,
    _split_sentences
)

# ---------------------------------------------------------------
# ğŸ” AnÃ¡lise de RedundÃ¢ncia Global
# ---------------------------------------------------------------
def run_redundancy(df, scope_key):
    st.header("ğŸ§¬ RedundÃ¢ncia entre UCs")
    st.caption(
        """
        Esta anÃ¡lise identifica **similaridades excessivas de conteÃºdo entre as Unidades Curriculares (UCs)**.
        Utiliza embeddings semÃ¢nticos (SBERT) para comparar ementas e detectar redundÃ¢ncias de temas,
        conceitos ou objetivos de aprendizagem.  
        Valores de similaridade altos indicam UCs potencialmente **sobrepostas ou repetitivas**.
        """
    )

    col_base = find_col(df, "Ementa") or find_col(df, "Objetos de conhecimento")
    if not col_base:
        st.error("Coluna de texto principal ('Ementa' ou 'Objetos de conhecimento') nÃ£o encontrada.")
        st.stop()

    textos = df[col_base].astype(str).apply(replace_semicolons).tolist()
    nomes = df["Nome da UC"].astype(str).tolist()

    with st.spinner("ğŸ§  Calculando embeddings e matriz de similaridade SBERT..."):
        emb = l2_normalize(sbert_embed(textos))
        S = np.dot(emb, emb.T)

    st.markdown("### ğŸ§® Matriz de Similaridade Global")
    df_mat = pd.DataFrame(S, index=nomes, columns=nomes)
    st.dataframe(
        df_mat.head(30)
        .style.format("{:.2f}")
        .background_gradient(cmap="RdYlGn_r", vmin=0, vmax=1),
        use_container_width=True,
    )
    export_table(scope_key, df_mat, "redundancia_matriz", "Matriz de Similaridade entre UCs")

    st.markdown("### ğŸ”— Pares de UCs com alta similaridade")
    thr = st.slider("Limiar de redundÃ¢ncia", 0.5, 0.95, 0.8)
    pares = []
    n = S.shape[0]
    for i in range(n):
        for j in range(i + 1, n):
            if S[i, j] >= thr:
                pares.append(
                    {"UC A": nomes[i], "UC B": nomes[j], "Similaridade": float(S[i, j])}
                )
    df_pares = pd.DataFrame(pares)
    if not df_pares.empty:
        df_pares = df_pares.sort_values("Similaridade", ascending=False)
        st.dataframe(df_pares.head(100), use_container_width=True)

        fig, ax = plt.subplots(figsize=(7, 4))
        sns.histplot(df_pares["Similaridade"], bins=10, kde=True, color="#3b5bdb", ax=ax)
        ax.set_title("DistribuiÃ§Ã£o das Similaridades (UCs Redundantes)")
        ax.set_xlabel("Similaridade")
        ax.set_ylabel("FrequÃªncia")
        st.pyplot(fig, use_container_width=True)

        export_table(scope_key, df_pares, "redundancia_pares", "Pares de UCs Redundantes")
    else:
        st.info("Nenhum par de UCs com similaridade acima do limiar escolhido.")

    export_zip_button(scope_key)

    st.markdown("---")
    st.subheader("ğŸ“˜ Como interpretar os resultados")
    st.markdown(
        """
        **1ï¸âƒ£ InterpretaÃ§Ã£o dos valores:**
        - **Similaridade â‰¥ 0.90** â†’ AltÃ­ssima redundÃ¢ncia (UCs possivelmente duplicadas).  
        - **Entre 0.75 e 0.90** â†’ RedundÃ¢ncia alta (conteÃºdos muito prÃ³ximos, possÃ­vel sobreposiÃ§Ã£o).  
        - **Entre 0.60 e 0.75** â†’ Similaridade mÃ©dia (Ã¡reas afins ou interdisciplinaridade natural).  
        - **Abaixo de 0.60** â†’ Similaridade baixa (UCs bem diferenciadas).  

        **2ï¸âƒ£ Como analisar:**
        - Utilize esta matriz para revisar o **portfÃ³lio de UCs** e evitar sobreposiÃ§Ãµes temÃ¡ticas.  
        - Avalie se redundÃ¢ncias representam **reforÃ§o formativo (positivo)** ou **repetiÃ§Ã£o desnecessÃ¡ria (negativo)**.  
        """
    )


# ---------------------------------------------------------------
# ğŸ§© ComparaÃ§Ã£o Frase-a-Frase entre duas UCs
# ---------------------------------------------------------------
def run_pair_analysis(df, scope_key):
    st.header("ğŸ”¬ AnÃ¡lise Frase a Frase entre UCs")
    st.caption(
        """
        Permite uma **comparaÃ§Ã£o semÃ¢ntica linha a linha** entre duas ementas selecionadas,
        destacando trechos semelhantes.  
        Ãštil para investigar redundÃ¢ncias detectadas na anÃ¡lise global e entender
        **quais passagens se repetem entre UCs**.
        """
    )

    col_base = find_col(df, "Ementa") or find_col(df, "Objetos de conhecimento")
    if not col_base:
        st.error("Coluna de texto nÃ£o encontrada.")
        st.stop()

    nomes = df["Nome da UC"].dropna().unique().tolist()
    uc_a = st.selectbox("ğŸ“˜ UC A", nomes)
    uc_b = st.selectbox("ğŸ“— UC B", [n for n in nomes if n != uc_a])

    text_a = replace_semicolons(df.loc[df["Nome da UC"] == uc_a, col_base].iloc[0])
    text_b = replace_semicolons(df.loc[df["Nome da UC"] == uc_b, col_base].iloc[0])
    ph_a, ph_b = _split_sentences(text_a), _split_sentences(text_b)

    if not ph_a or not ph_b:
        st.warning("NÃ£o hÃ¡ frases suficientes para comparar.")
        return

    emb_a, emb_b = sbert_embed(ph_a), sbert_embed(ph_b)
    sim = cosine_similarity(emb_a, emb_b)

    rows = []
    for i in range(len(ph_a)):
        j = np.argmax(sim[i])
        rows.append(
            {"Similaridade": sim[i, j], "Trecho A": ph_a[i], "Trecho B": ph_b[j]}
        )
    df_out = pd.DataFrame(rows).sort_values("Similaridade", ascending=False)

    st.markdown("### ğŸ§© Trechos mais semelhantes")
    st.dataframe(
        df_out.head(15).style.format({"Similaridade": "{:.3f}"}),
        use_container_width=True,
    )
    export_table(scope_key, df_out, f"redundancia_{uc_a}_vs_{uc_b}", "RedundÃ¢ncia Frase a Frase")
    export_zip_button(scope_key)

    st.markdown("---")
    st.subheader("ğŸ“˜ Como interpretar")
    st.markdown(
        f"""
        **1ï¸âƒ£ O que observar entre '{uc_a}' e '{uc_b}':**
        - Similaridade â‰¥ 0.85 â†’ repetiÃ§Ã£o literal.  
        - 0.65â€“0.85 â†’ parÃ¡frases conceituais.  
        - Abaixo de 0.65 â†’ apenas relaÃ§Ã£o tangencial.  

        **2ï¸âƒ£ AplicaÃ§Ãµes prÃ¡ticas:**
        - Localizar duplicaÃ§Ãµes e **revisar UCs redundantes**.  
        - Apoiar decisÃµes de **fusÃ£o ou reformulaÃ§Ã£o textual**.  
        """
    )


# ---------------------------------------------------------------
# ğŸ§­ Matriz de Similaridade â€” Objetos Ã— CompetÃªncias & DCN
# ---------------------------------------------------------------
def run_alignment_matrix(df, scope_key):
    st.header("ğŸ§­ Matriz de Similaridade (Objetos Ã— CompetÃªncias & DCN)")
    st.caption(
        """
        Mede o quanto cada UC estÃ¡ semanticamente **alinhada** entre:
        - **Objetos de Conhecimento Ã— CompetÃªncias do Egresso**  
        - **Objetos de Conhecimento Ã— CompetÃªncias das DCNs**

        Valores prÃ³ximos de **1.00** indicam **forte coerÃªncia** entre o que Ã© ensinado,
        o perfil do egresso e as competÃªncias normativas das DCNs.
        """
    )

    col_obj = find_col(df, "Objetos de conhecimento")
    col_comp = find_col(df, "CompetÃªncias do Perfil do Egresso")
    col_dcn = find_col(df, "CompetÃªncias DCN")

    if not col_obj or not (col_comp or col_dcn):
        st.error("Ã‰ necessÃ¡rio ter colunas de 'Objetos de conhecimento' e 'CompetÃªncias' (Egresso/DCN).")
        return

    df_valid = df.dropna(subset=[col_obj])
    textos_obj = df_valid[col_obj].astype(str).tolist()
    textos_comp = df_valid[col_comp].astype(str).tolist() if col_comp else None
    textos_dcn = df_valid[col_dcn].astype(str).tolist() if col_dcn else None
    nomes = df_valid["Nome da UC"].astype(str).tolist()

    emb_obj = l2_normalize(sbert_embed(textos_obj))
    results = []

    if textos_comp:
        emb_comp = l2_normalize(sbert_embed(textos_comp))
        sim_comp = np.diag(np.dot(emb_obj, emb_comp.T))
        results.append(("Objetos Ã— CompetÃªncias Egresso", sim_comp))
    if textos_dcn:
        emb_dcn = l2_normalize(sbert_embed(textos_dcn))
        sim_dcn = np.diag(np.dot(emb_obj, emb_dcn.T))
        results.append(("Objetos Ã— CompetÃªncias DCN", sim_dcn))

    df_res = pd.DataFrame({"UC": nomes})
    for label, vals in results:
        df_res[label] = vals

    st.markdown("### ğŸ“ˆ Similaridade entre DimensÃµes")
    st.dataframe(df_res, use_container_width=True)
    export_table(scope_key, df_res, "matriz_objetos_competencias", "Matriz Objetos Ã— CompetÃªncias/DCN")

    st.markdown("### ğŸŒ¡ï¸ Mapa de Calor de Alinhamento")
    fig, ax = plt.subplots(figsize=(8, 5))
    sns.heatmap(df_res.set_index("UC"), annot=True, cmap="YlGnBu", fmt=".2f", linewidths=0.5, ax=ax)
    ax.set_title("Matriz de Similaridade (Objetos Ã— CompetÃªncias / DCN)")
    st.pyplot(fig, use_container_width=True)

    export_zip_button(scope_key)

    st.markdown("---")
    st.subheader("ğŸ“˜ Como interpretar os resultados")
    st.markdown(
        """
        - **â‰¥ 0.85:** Forte coerÃªncia entre o que Ã© ensinado e o que se espera formar.  
        - **0.65â€“0.85:** CoerÃªncia moderada; hÃ¡ alinhamento geral, mas com dispersÃµes.  
        - **< 0.65:** Baixa coerÃªncia; conteÃºdos e competÃªncias podem estar desconectados.  

        ğŸ’¡ **Dica:** UCs com baixa correlaÃ§Ã£o simultÃ¢nea entre *Objetos Ã— CompetÃªncias do Egresso* e *Objetos Ã— DCN* devem ser revisadas quanto Ã  clareza de objetivos e aderÃªncia normativa.
        """
    )
